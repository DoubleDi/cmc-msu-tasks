{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "import string\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xml_to_df(xml_data):\n",
    "    root = ET.XML(xml_data) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            if subchild.tag == 'evaluation':\n",
    "                record[subchild.tag] = subchild.text.strip().replace('\\n', ' ')\n",
    "            else:\n",
    "                record[subchild.tag] = subchild.text.strip().replace('\\n', ' ')\n",
    "        all_records.append(record)\n",
    "    return pd.DataFrame(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenizer = RegexpTokenizer('\\w+|\\S+')\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "def stem_text(text):\n",
    "    r = RussianStemmer()\n",
    "    return [r.stem(word) for word in text]\n",
    "\n",
    "def prepare_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\!\\\"\\#\\$\\%\\&\\\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\\\\\]\\^\\_\\`\\{\\|\\}\\~]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим данные в формате XML и запишем их в DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_train_data = open('train/news_eval_train.xml').read()\n",
    "xml_test_data = open('test/news_eval_test.xml').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "      <th>speech</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Далее в своей проповеди он напомнил, что по би...</td>\n",
       "      <td>http://www.blagovest-info.ru/index.php?ss=2&amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>Меня отпустили. У Коли @nlyaskin забирают вещи...</td>\n",
       "      <td>http://asiareport.ru/index.php/news/14440-chir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+-</td>\n",
       "      <td>Мои игроки не разочаровали меня, даже слегка н...</td>\n",
       "      <td>http://www.soccer.ru/news/290704.shtml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>В интервью РИА Новости уполномоченный по права...</td>\n",
       "      <td>http://www.rosbalt.ru/federal/2012/04/08/96718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>+-</td>\n",
       "      <td>Психологи начнут работать с двумя девушками, Д...</td>\n",
       "      <td>http://www.rosbalt.ru/federal/2012/04/08/96718...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation                                             speech  \\\n",
       "0          0  Далее в своей проповеди он напомнил, что по би...   \n",
       "1          -  Меня отпустили. У Коли @nlyaskin забирают вещи...   \n",
       "2         +-  Мои игроки не разочаровали меня, даже слегка н...   \n",
       "3          0  В интервью РИА Новости уполномоченный по права...   \n",
       "4         +-  Психологи начнут работать с двумя девушками, Д...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.blagovest-info.ru/index.php?ss=2&am...  \n",
       "1  http://asiareport.ru/index.php/news/14440-chir...  \n",
       "2             http://www.soccer.ru/news/290704.shtml  \n",
       "3  http://www.rosbalt.ru/federal/2012/04/08/96718...  \n",
       "4  http://www.rosbalt.ru/federal/2012/04/08/96718...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = xml_to_df(xml_train_data)\n",
    "df_test = xml_to_df(xml_test_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В данных встречаются лишние оценки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '+-', '-', '0'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '+-', '-', '--', '-no', '0', 'n-', 'n0', 'no'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_test.evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удаляем ненужные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "      <th>speech</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Джазбэнд под руководством Пеппе Сервилло, кото...</td>\n",
       "      <td>http://www.inmsk.ru/news_culture/20120914/3516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>Посредством этих структур десяткам тысяч избир...</td>\n",
       "      <td>http://www.dw.de/dw/article/0,,16237071,00.htm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>Появилось очень много бедных избирателей. В се...</td>\n",
       "      <td>http://www.dw.de/dw/article/0,,16237071,00.htm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>За теленовостями - главным источником информац...</td>\n",
       "      <td>http://www.dw.de/dw/article/0,,16237071,00.htm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>Такого раньше никогда не было, чтобы местные ч...</td>\n",
       "      <td>http://www.dw.de/dw/article/0,,16237071,00.htm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation                                             speech  \\\n",
       "0          0  Джазбэнд под руководством Пеппе Сервилло, кото...   \n",
       "2          -  Посредством этих структур десяткам тысяч избир...   \n",
       "3          -  Появилось очень много бедных избирателей. В се...   \n",
       "4          -  За теленовостями - главным источником информац...   \n",
       "5          -  Такого раньше никогда не было, чтобы местные ч...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.inmsk.ru/news_culture/20120914/3516...  \n",
       "2  http://www.dw.de/dw/article/0,,16237071,00.htm...  \n",
       "3  http://www.dw.de/dw/article/0,,16237071,00.htm...  \n",
       "4  http://www.dw.de/dw/article/0,,16237071,00.htm...  \n",
       "5  http://www.dw.de/dw/article/0,,16237071,00.htm...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[df_test.evaluation != '+-']\n",
    "df_test = df_test[df_test.evaluation != '--']\n",
    "df_test = df_test[df_test.evaluation != '-no']\n",
    "df_test = df_test[df_test.evaluation != 'n-']\n",
    "df_test = df_test[df_test.evaluation != 'n0']\n",
    "df_test = df_test[df_test.evaluation != 'no']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation</th>\n",
       "      <th>speech</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Далее в своей проповеди он напомнил, что по би...</td>\n",
       "      <td>http://www.blagovest-info.ru/index.php?ss=2&amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>Меня отпустили. У Коли @nlyaskin забирают вещи...</td>\n",
       "      <td>http://asiareport.ru/index.php/news/14440-chir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>В интервью РИА Новости уполномоченный по права...</td>\n",
       "      <td>http://www.rosbalt.ru/federal/2012/04/08/96718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Бывший главный тренер сборной Англии Грэм Тэйл...</td>\n",
       "      <td>http://www.sports.ru/football/139754406.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-</td>\n",
       "      <td>На телах жертв были обнаружены многочисленные ...</td>\n",
       "      <td>http://moldinfo.ru/narod/2939-jitel-vengerskoy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation                                             speech  \\\n",
       "0          0  Далее в своей проповеди он напомнил, что по би...   \n",
       "1          -  Меня отпустили. У Коли @nlyaskin забирают вещи...   \n",
       "3          0  В интервью РИА Новости уполномоченный по права...   \n",
       "7          0  Бывший главный тренер сборной Англии Грэм Тэйл...   \n",
       "8          -  На телах жертв были обнаружены многочисленные ...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.blagovest-info.ru/index.php?ss=2&am...  \n",
       "1  http://asiareport.ru/index.php/news/14440-chir...  \n",
       "3  http://www.rosbalt.ru/federal/2012/04/08/96718...  \n",
       "7       http://www.sports.ru/football/139754406.html  \n",
       "8  http://moldinfo.ru/narod/2939-jitel-vengerskoy...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[df_train.evaluation != '+-']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выборки для обучения и тестирования**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.speech.values\n",
    "y_train = df_train.evaluation.values\n",
    "\n",
    "X_test = df_test.speech.values\n",
    "y_test = df_test.evaluation.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обработаем текст**\n",
    "\n",
    "Удаляются все знаки пунктуации, текст токенизируется и осуществляется стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    X = [prepare_text(text) for text in X]\n",
    "    X = [tokenize(text) for text in X]\n",
    "    X = [stem_text(text) for text in X]\n",
    "    X = [' '.join(words) for words in X]\n",
    "    return [prepare_text(text) for text in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_prepare = preprocess(X_train)\n",
    "X_test_prepare = preprocess(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для каждой модели будем брать подсчет энграмм и веса tf-idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_reg = Pipeline([('count', CountVectorizer(ngram_range=(1, 2), min_df=1)), \n",
    "                  ('log_reg', LogisticRegression())])\n",
    "model_reg_tfidf = Pipeline([('tf-idf', TfidfVectorizer(ngram_range=(1, 1), min_df=3)), \n",
    "                         ('log_reg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод опорных векторов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_svm = Pipeline([('count', CountVectorizer(ngram_range=(1, 1), min_df=1)),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
    "model_svm_tfidf = Pipeline([('tf-idf', TfidfVectorizer(ngram_range=(1, 1), min_df=1)),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наивный байесовский классификатор с мультиномиальной моделью событий**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nbm = Pipeline([('count', CountVectorizer(ngram_range=(1, 1), min_df=3)), \n",
    "                     ('nb', MultinomialNB()),])\n",
    "model_nbm_tfidf = Pipeline([('tf-idf', TfidfVectorizer(ngram_range=(1, 1), min_df=9)), \n",
    "                     ('nb', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наивный байесовский классификатор с Бернуллиевской моделью событий**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_nbb = Pipeline([('count', CountVectorizer(ngram_range=(1, 1), min_df=1)), \n",
    "                     ('nb', BernoulliNB()),])\n",
    "model_nbb_tfidf = Pipeline([('tf-idf', TfidfVectorizer(ngram_range=(1, 1), min_df=3)), \n",
    "                     ('nb', BernoulliNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучаем модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf-idf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tr...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.fit(X_train_prepare, y_train)\n",
    "model_reg_tfidf.fit(X_train_prepare, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf-idf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tr...ty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm.fit(X_train_prepare, y_train)\n",
    "model_svm_tfidf.fit(X_train_prepare, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf-idf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=9,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tr...True,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nbm.fit(X_train_prepare, y_train)\n",
    "model_nbm_tfidf.fit(X_train_prepare, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tf-idf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=Tr...  vocabulary=None)), ('nb', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nbb.fit(X_train_prepare, y_train)\n",
    "model_nbb_tfidf.fit(X_train_prepare, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предсказываем по текстовой выборке**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_reg = model_reg.predict(X_test_prepare)\n",
    "preds_reg_tfidf = model_reg_tfidf.predict(X_test_prepare)\n",
    "\n",
    "preds_svm = model_svm.predict(X_test_prepare)\n",
    "preds_svm_tfidf = model_svm_tfidf.predict(X_test_prepare)\n",
    "\n",
    "preds_nbm = model_nbm.predict(X_test_prepare)\n",
    "preds_nbm_tfidf = model_nbm_tfidf.predict(X_test_prepare)\n",
    "\n",
    "preds_nbb = model_nbb.predict(X_test_prepare)\n",
    "preds_nbb_tfidf = model_nbb_tfidf.predict(X_test_prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В качестве оценки выводим F-меру**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.57      0.66      0.61      1448\n",
      "          -       0.66      0.77      0.71      1890\n",
      "          0       0.53      0.30      0.39      1235\n",
      "\n",
      "avg / total       0.60      0.61      0.59      4573\n",
      "\n",
      "LogisticRegression with tf-idf: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.61      0.64      0.62      1448\n",
      "          -       0.62      0.86      0.72      1890\n",
      "          0       0.60      0.20      0.30      1235\n",
      "\n",
      "avg / total       0.61      0.61      0.57      4573\n",
      "\n",
      "SGDClassifier: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.53      0.68      0.59      1448\n",
      "          -       0.70      0.65      0.68      1890\n",
      "          0       0.46      0.36      0.40      1235\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4573\n",
      "\n",
      "SGDClassifier with tf-idf: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.64      0.58      0.61      1448\n",
      "          -       0.56      0.92      0.70      1890\n",
      "          0       0.69      0.10      0.17      1235\n",
      "\n",
      "avg / total       0.62      0.59      0.53      4573\n",
      "\n",
      "MultinomialNB: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.57      0.72      0.64      1448\n",
      "          -       0.71      0.70      0.71      1890\n",
      "          0       0.52      0.37      0.43      1235\n",
      "\n",
      "avg / total       0.62      0.62      0.61      4573\n",
      "\n",
      "MultinomialNB with tf-idf: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.63      0.59      0.61      1448\n",
      "          -       0.58      0.87      0.69      1890\n",
      "          0       0.60      0.18      0.28      1235\n",
      "\n",
      "avg / total       0.60      0.59      0.55      4573\n",
      "\n",
      "BernoulliNB: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.66      0.57      0.61      1448\n",
      "          -       0.56      0.89      0.68      1890\n",
      "          0       0.60      0.15      0.24      1235\n",
      "\n",
      "avg / total       0.60      0.59      0.54      4573\n",
      "\n",
      "BernoulliNB with tf-idf: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.59      0.68      0.63      1448\n",
      "          -       0.69      0.72      0.70      1890\n",
      "          0       0.53      0.41      0.46      1235\n",
      "\n",
      "avg / total       0.62      0.62      0.62      4573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"LogisticRegression: \\n\", classification_report(y_test, preds_reg)\n",
    "print \"LogisticRegression with tf-idf: \\n\", classification_report(y_test, preds_reg_tfidf)\n",
    "\n",
    "print \"SGDClassifier: \\n\", classification_report(y_test, preds_svm)\n",
    "print \"SGDClassifier with tf-idf: \\n\", classification_report(y_test, preds_svm_tfidf)\n",
    "\n",
    "print \"MultinomialNB: \\n\", classification_report(y_test, preds_nbm)\n",
    "print \"MultinomialNB with tf-idf: \\n\", classification_report(y_test, preds_nbm_tfidf)\n",
    "\n",
    "print \"BernoulliNB: \\n\", classification_report(y_test, preds_nbb)\n",
    "print \"BernoulliNB with tf-idf: \\n\", classification_report(y_test, preds_nbb_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отсортированные результаты**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| BernoulliNB tf-idf | MultinomialNB   | LogisticRegression | SGDClassifier   | LogisticRegression tf-idf | MultinomialNB tf-idf   | BernoulliNB |  SGDClassifier tf-idf  |\n",
    "|------|------|------|------|------|------|------|------|\n",
    "|    0.62  | 0.61 |   0.59  | 0.58|  0.57   | 0.55|   0.54  |0.53|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Дополнительно была рассомтрена модель с Gradient Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_gb = Pipeline([('count', CountVectorizer(ngram_range=(1, 1))), \n",
    "                  ('grad_boost', GradientBoostingClassifier(max_depth=10, verbose=True, n_estimators=100))])\n",
    "model_gb_tfidf = Pipeline([('count', TfidfVectorizer(ngram_range=(1, 1), min_df=1)), \n",
    "                         ('grad_boost', GradientBoostingClassifier(max_depth=10, verbose=True, n_estimators=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4011.3752           37.92s\n",
      "         2        3889.3819           37.98s\n",
      "         3        3776.9388           37.96s\n",
      "         4        3671.5761           38.40s\n",
      "         5        3589.6046           38.32s\n",
      "         6        3510.7869           38.76s\n",
      "         7        3440.9756           38.50s\n",
      "         8        3381.6132           37.81s\n",
      "         9        3311.6199           37.74s\n",
      "        10        3245.0917           37.53s\n",
      "        20        2809.8752           31.80s\n",
      "        30        2549.7547           25.99s\n",
      "        40        2371.8570           21.03s\n",
      "        50        2226.1708           16.80s\n",
      "        60        2102.8243           13.00s\n",
      "        70        1991.7791            9.47s\n",
      "        80        1903.9930            6.14s\n",
      "        90        1822.2759            2.99s\n",
      "       100        1753.0031            0.00s\n"
     ]
    }
   ],
   "source": [
    "model_gb.fit(X_train_prepare, y_train)\n",
    "preds_bg = model_gb.predict(X_test_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        4002.4587           49.10s\n",
      "         2        3869.1866           49.54s\n",
      "         3        3742.4583           49.66s\n",
      "         4        3635.7862           49.49s\n",
      "         5        3537.3250           49.23s\n",
      "         6        3444.3293           49.18s\n",
      "         7        3373.2171           48.56s\n",
      "         8        3301.4498           47.92s\n",
      "         9        3227.9904           48.01s\n",
      "        10        3162.2816           47.40s\n",
      "        20        2717.3342           40.00s\n",
      "        30        2443.9638           33.48s\n",
      "        40        2239.3267           27.81s\n",
      "        50        2074.4934           22.62s\n",
      "        60        1941.9084           17.80s\n",
      "        70        1829.0827           13.16s\n",
      "        80        1729.8579            8.69s\n",
      "        90        1638.9007            4.31s\n",
      "       100        1553.8825            0.00s\n"
     ]
    }
   ],
   "source": [
    "model_gb_tfidf.fit(X_train_prepare, y_train)\n",
    "preds_bg_tfidf = model_gb_tfidf.predict(X_test_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.59      0.58      0.58      1448\n",
      "          -       0.58      0.82      0.68      1890\n",
      "          0       0.46      0.17      0.24      1235\n",
      "\n",
      "avg / total       0.55      0.57      0.53      4573\n",
      "\n",
      "GradientBoostingClassifier with tf-idf: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.58      0.56      0.57      1448\n",
      "          -       0.58      0.79      0.67      1890\n",
      "          0       0.47      0.22      0.30      1235\n",
      "\n",
      "avg / total       0.55      0.56      0.54      4573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"GradientBoostingClassifier: \\n\", classification_report(y_test, preds_bg)\n",
    "print \"GradientBoostingClassifier with tf-idf: \\n\", classification_report(y_test, preds_bg_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
